{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tools import init_paths\n",
    "\n",
    "from config import cfg\n",
    "from config import update_config\n",
    "from core.loss import JointsMSELoss\n",
    "from core.function import validate\n",
    "from utils.utils import create_logger\n",
    "\n",
    "import dataset\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_my_config():\n",
    "    cfg.defrost()\n",
    "\n",
    "    cfg.merge_from_file('experiments/mpii/hrnet/w32_256x256_adam_lr1e-3.yaml')\n",
    "\n",
    "    opts = [\"TEST.MODEL_FILE\", \"/mnt/models/HRNet/pose_mpii/pose_hrnet_w32_256x256.pth\"]\n",
    "    cfg.merge_from_list(opts)\n",
    "\n",
    "    cfg.OUTPUT_DIR = \"output_test\"\n",
    "\n",
    "    cfg.LOG_DIR = \"log_test\"\n",
    "\n",
    "    cfg.freeze()\n",
    "\n",
    "\n",
    "def main():\n",
    "    update_my_config()\n",
    "\n",
    "    logger, final_output_dir, tb_log_dir = create_logger(\n",
    "        cfg, \"experiments/mpii/hrnet/w32_256x256_adam_lr1e-3.yaml\", 'valid')\n",
    "\n",
    "    #logger.info(pprint.pformat(args))\n",
    "    logger.info(cfg)\n",
    "\n",
    "    # cudnn related setting\n",
    "    cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "    torch.backends.cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "    torch.backends.cudnn.enabled = cfg.CUDNN.ENABLED\n",
    "\n",
    "    model = eval('models.'+cfg.MODEL.NAME+'.get_pose_net')(\n",
    "        cfg, is_train=False\n",
    "    )\n",
    "\n",
    "    if cfg.TEST.MODEL_FILE:\n",
    "        logger.info('=> loading model from {}'.format(cfg.TEST.MODEL_FILE))\n",
    "        model.load_state_dict(torch.load(cfg.TEST.MODEL_FILE), strict=False)\n",
    "    else:\n",
    "        model_state_file = os.path.join(\n",
    "            final_output_dir, 'final_state.pth'\n",
    "        )\n",
    "        logger.info('=> loading model from {}'.format(model_state_file))\n",
    "        model.load_state_dict(torch.load(model_state_file))\n",
    "\n",
    "    model = torch.nn.DataParallel(model, device_ids=cfg.GPUS).cuda()\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = JointsMSELoss(\n",
    "        use_target_weight=cfg.LOSS.USE_TARGET_WEIGHT\n",
    "    ).cuda()\n",
    "\n",
    "    # Data loading code\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    valid_dataset = eval('dataset.'+cfg.DATASET.DATASET)(\n",
    "        cfg, cfg.DATASET.ROOT, cfg.DATASET.TEST_SET, False,\n",
    "        transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=cfg.TEST.BATCH_SIZE_PER_GPU*len(cfg.GPUS),\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # evaluate on validation set\n",
    "    validate(cfg, valid_loader, valid_dataset, model, criterion,\n",
    "             final_output_dir, tb_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTO_RESUME: True\n",
      "CUDNN:\n",
      "  BENCHMARK: True\n",
      "  DETERMINISTIC: False\n",
      "  ENABLED: True\n",
      "DATASET:\n",
      "  COLOR_RGB: True\n",
      "  DATASET: mpii\n",
      "  DATA_FORMAT: jpg\n",
      "  FLIP: True\n",
      "  HYBRID_JOINTS_TYPE: \n",
      "  NUM_JOINTS_HALF_BODY: 8\n",
      "  PROB_HALF_BODY: -1.0\n",
      "  ROOT: data/mpii/\n",
      "  ROT_FACTOR: 30\n",
      "  SCALE_FACTOR: 0.25\n",
      "  SELECT_DATA: False\n",
      "  TEST_SET: valid\n",
      "  TRAIN_SET: train\n",
      "DATA_DIR: \n",
      "DEBUG:\n",
      "  DEBUG: True\n",
      "  SAVE_BATCH_IMAGES_GT: True\n",
      "  SAVE_BATCH_IMAGES_PRED: True\n",
      "  SAVE_HEATMAPS_GT: True\n",
      "  SAVE_HEATMAPS_PRED: True\n",
      "GPUS: (0, 1, 2, 3)\n",
      "LOG_DIR: log_test\n",
      "LOSS:\n",
      "  TOPK: 8\n",
      "  USE_DIFFERENT_JOINTS_WEIGHT: False\n",
      "  USE_OHKM: False\n",
      "  USE_TARGET_WEIGHT: True\n",
      "MODEL:\n",
      "  EXTRA:\n",
      "    FINAL_CONV_KERNEL: 1\n",
      "    PRETRAINED_LAYERS: ['conv1', 'bn1', 'conv2', 'bn2', 'layer1', 'transition1', 'stage2', 'transition2', 'stage3', 'transition3', 'stage4']\n",
      "    STAGE2:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4]\n",
      "      NUM_BRANCHES: 2\n",
      "      NUM_CHANNELS: [32, 64]\n",
      "      NUM_MODULES: 1\n",
      "    STAGE3:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4, 4]\n",
      "      NUM_BRANCHES: 3\n",
      "      NUM_CHANNELS: [32, 64, 128]\n",
      "      NUM_MODULES: 4\n",
      "    STAGE4:\n",
      "      BLOCK: BASIC\n",
      "      FUSE_METHOD: SUM\n",
      "      NUM_BLOCKS: [4, 4, 4, 4]\n",
      "      NUM_BRANCHES: 4\n",
      "      NUM_CHANNELS: [32, 64, 128, 256]\n",
      "      NUM_MODULES: 3\n",
      "  HEATMAP_SIZE: [64, 64]\n",
      "  IMAGE_SIZE: [256, 256]\n",
      "  INIT_WEIGHTS: True\n",
      "  NAME: pose_hrnet\n",
      "  NUM_JOINTS: 16\n",
      "  PRETRAINED: models/pytorch/imagenet/hrnet_w32-36af842e.pth\n",
      "  SIGMA: 2\n",
      "  TAG_PER_JOINT: True\n",
      "  TARGET_TYPE: gaussian\n",
      "OUTPUT_DIR: output_test\n",
      "PIN_MEMORY: True\n",
      "PRINT_FREQ: 100\n",
      "RANK: 0\n",
      "TEST:\n",
      "  BATCH_SIZE_PER_GPU: 32\n",
      "  BBOX_THRE: 1.0\n",
      "  COCO_BBOX_FILE: \n",
      "  FLIP_TEST: True\n",
      "  IMAGE_THRE: 0.1\n",
      "  IN_VIS_THRE: 0.0\n",
      "  MODEL_FILE: /mnt/models/HRNet/pose_mpii/pose_hrnet_w32_256x256.pth\n",
      "  NMS_THRE: 0.6\n",
      "  OKS_THRE: 0.5\n",
      "  POST_PROCESS: True\n",
      "  SHIFT_HEATMAP: True\n",
      "  SOFT_NMS: False\n",
      "  USE_GT_BBOX: False\n",
      "TRAIN:\n",
      "  BATCH_SIZE_PER_GPU: 32\n",
      "  BEGIN_EPOCH: 0\n",
      "  CHECKPOINT: \n",
      "  END_EPOCH: 210\n",
      "  GAMMA1: 0.99\n",
      "  GAMMA2: 0.0\n",
      "  LR: 0.001\n",
      "  LR_FACTOR: 0.1\n",
      "  LR_STEP: [170, 200]\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  OPTIMIZER: adam\n",
      "  RESUME: False\n",
      "  SHUFFLE: True\n",
      "  WD: 0.0001\n",
      "WORKERS: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output_test/mpii/pose_hrnet/w32_256x256_adam_lr1e-3\n",
      "=> creating log_test/mpii/pose_hrnet/w32_256x256_adam_lr1e-3_2019-10-31-02-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> loading model from /mnt/models/HRNet/pose_mpii/pose_hrnet_w32_256x256.pth\n",
      "=> load 2958 samples\n",
      "Test: [0/24]\tTime 19.583 (19.583)\tLoss 0.0005 (0.0005)\tAccuracy 0.876 (0.876)\n",
      "| Arch | Head | Shoulder | Elbow | Wrist | Hip | Knee | Ankle | Mean | Mean@0.1 |\n",
      "|---|---|---|---|---|---|---|---|---|---|\n",
      "| pose_hrnet | 97.101 | 95.941 | 90.336 | 86.449 | 89.095 | 87.084 | 83.278 | 90.330 | 37.702 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Head', 97.10095497953616), ('Shoulder', 95.94089673913044), ('Elbow', 90.33585228844147), ('Wrist', 86.44887639077518), ('Hip', 89.09468549632814), ('Knee', 87.0839159249281), ('Ankle', 83.27820897720389), ('Mean', 90.3304709862087), ('Mean@0.1', 37.70231589903722)]) 90.3304709862087\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
